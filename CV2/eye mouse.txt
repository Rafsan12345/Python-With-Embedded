import cv2
import time
import numpy as np
import pyautogui
import mediapipe as mp
cap = cv2.VideoCapture(0)
face_detector = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)
drawing_utils = mp.solutions.drawing_utils
s_w, s_h = pyautogui.size()
in_y = 0
while True:
    _,frame = cap.read()
    frame = cv2.flip(frame,1)
    rgb_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)
    frame_h,frame_w,_ = frame.shape
    output = face_detector.process(rgb_frame)
    landmark_points = output.multi_face_landmarks

    if landmark_points:
        landmarks = landmark_points[0].landmark
        for id,landmark in  enumerate (landmarks[474:478]):
            x = int(landmark.x * frame_w)
            y = int(landmark.y * frame_h)
            cv2.circle(frame,(x,y),3,(0,255,0))
            if id ==1:
                in_x = s_w / frame_w * x
                in_y = s_h / frame_h * y
                #pyautogui.moveTo(in_x, in_y)
        left = [landmarks[145],landmarks[159]]
        for landmark in left:
            x = int(landmark.x * frame_w)
            y = int(landmark.y * frame_h)
            cv2.circle(frame, (x, y), 3, (0, 255, 255))
        print(left[0].y-left[1].y) #diffrence

        if (left[0].y-left[1].y)<0.004:
            print("click")

            #print(len(landmarks))







    cv2.imshow("img",frame)
    cv2.waitKey(1)